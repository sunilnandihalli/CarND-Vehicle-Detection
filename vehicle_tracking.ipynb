{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.misc import imresize,imsave\n",
    "import glob\n",
    "import pickle\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from scipy.ndimage.measurements import label\n",
    "from collections import deque\n",
    "import random\n",
    "import os\n",
    "\n",
    "matplotlib.rcParams['figure.figsize']=[24.0,16.0]\n",
    "red = (1.0,0,0)\n",
    "green = (0,1.0,0)\n",
    "blue = (0,0,1.0)\n",
    "white = (1.0,1.0,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_vehicles = '/Users/sunilsn/Desktop/self-driving-car-nanodegree/datasets/vehicle-tracking/non-vehicles/'\n",
    "cars = glob.glob('/Users/sunilsn/Desktop/self-driving-car-nanodegree/datasets/vehicle-tracking/vehicles/*/*.png')\n",
    "non_cars = glob.glob(non_vehicles+'*/*.png')\n",
    "cutouts = glob.glob('/Users/sunilsn/Desktop/self-driving-car-nanodegree/datasets/vehicle-tracking/cutouts/cutout*.jpg')\n",
    "sample_frame = '/Users/sunilsn/Desktop/self-driving-car-nanodegree/datasets/vehicle-tracking/cutouts/bbox-example-image.jpg'\n",
    "project_video = '/Users/sunilsn/Desktop/self-driving-car-nanodegree/projects/CarND-Vehicle-Detection/project_video.mp4'\n",
    "test_video = '/Users/sunilsn/Desktop/self-driving-car-nanodegree/projects/CarND-Vehicle-Detection/test_video.mp4'\n",
    "project_video_output = '/Users/sunilsn/Desktop/self-driving-car-nanodegree/projects/CarND-Vehicle-Detection/project_video_output.mp4'\n",
    "test_video_output = '/Users/sunilsn/Desktop/self-driving-car-nanodegree/projects/CarND-Vehicle-Detection/test_video_output.mp4'\n",
    "\n",
    "\n",
    "num_examples = None\n",
    "cars = cars[:num_examples]\n",
    "non_cars = non_cars[:num_examples]\n",
    "cspace = 'YCrCb' #'RGB'\n",
    "#cspace = 'RGB'\n",
    "spatial = 32\n",
    "hist_bins = 32\n",
    "hist_range = (0,1)\n",
    "num_orientation_bins = 12\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_read(img_fname):\n",
    "    ret = mpimg.imread(img_fname)\n",
    "    if ret.dtype == np.uint8:\n",
    "        ret = ret.astype(np.float32)/255\n",
    "    elif ret.dtype == np.float32:\n",
    "        pass\n",
    "    else:\n",
    "        print('unhandled image type : ',ret.dtype,img_fname)\n",
    "    if np.max(ret)>1:\n",
    "        print('max value in image greater than 1 ',img_fname)\n",
    "    return ret\n",
    "\n",
    "def img_write(img_fname,img):\n",
    "    imsave(img_fname,img)\n",
    "    \n",
    "def bin_spatial(img, size):\n",
    "    resized_img = cv2.resize(img, size)\n",
    "    features = resized_img.ravel() \n",
    "    return features\n",
    "\n",
    "def color_hist(img, nbins, bins_range):\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    return hist_features\n",
    "\n",
    "def get_hog_features(ch, num_orientation_bins, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    return hog(ch, orientations=num_orientation_bins, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                   cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                   visualise=vis, feature_vector=feature_vec,block_norm='L2-Hys')\n",
    "    \n",
    "\n",
    "def convert_color(image,cspace):\n",
    "    if cspace != 'RGB':\n",
    "        flag = {'HSV':cv2.COLOR_RGB2HSV,'HLS':cv2.COLOR_RGB2HLS,'YUV':cv2.COLOR_RGB2YUV,\n",
    "                'LUV':cv2.COLOR_RGB2LUV,'YCrCb':cv2.COLOR_RGB2YCrCb}\n",
    "        converted_image = cv2.cvtColor(image,flag[cspace])\n",
    "    else: converted_image = np.copy(image) \n",
    "    return converted_image\n",
    "\n",
    "def intersects(b1,b2):\n",
    "    (lx1,ly1),(rx1,ry1) = b1\n",
    "    (lx2,ly2),(rx2,ry2) = b2\n",
    "    if ry1 <ly2  or ly1>ry2 or rx1<lx2 or rx2<lx1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def gen_images(image,augment_dir,num_images=100,exclude_bboxes=[],size=64,image_bbox=None):\n",
    "    try:\n",
    "        os.mkdir(augment_dir)\n",
    "    except:\n",
    "        print('error creating directory')\n",
    "    if image_bbox is not None:\n",
    "        (x1,y1),(x2,y2) = image_bbox\n",
    "        cimg = image[y1:y2,x1:x2]\n",
    "    else:\n",
    "        cimg = image\n",
    "    for aimg,index in zip(list(itertools.islice(rand_sub_images(cimg,exclude_bboxes,size),num_images)),range(num_images)):\n",
    "        img_write(augment_dir+'/image_%05d.png'%(index),aimg)\n",
    "    \n",
    "def rand_sub_images(img,exclude_bboxes,size):\n",
    "    ymax = img.shape[1]\n",
    "    xmax = img.shape[0]\n",
    "    while True:\n",
    "        x,y = random.randrange(ymax-size),random.randrange(xmax-size)\n",
    "        bbox=((x,y),(x+size,y+size))\n",
    "        if all([intersects(bbox,ebox)==False for ebox in exclude_bboxes]):\n",
    "            yield img[y:y+size,x:x+size]            \n",
    "            \n",
    "def gen_car_images(img,car_bboxes):\n",
    "    for (x1,y1),(x2,y2) in car_bboxes:\n",
    "        yield img[y1:y2,x1:x2]\n",
    "        \n",
    "    \n",
    "def image_features(image, cspace, spatial_size, hist_bins, hist_range):\n",
    "    converted_image = convert_color(image,cspace)\n",
    "    feature_image = cv2.resize(converted_image,(64,64))\n",
    "    spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "    hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "    f = lambda ch: get_hog_features(feature_image[:,:,ch],num_orientation_bins,pix_per_cell,cell_per_block)\n",
    "    hog_features = np.hstack((f(0),f(1),f(2)))\n",
    "    final_features = np.hstack((spatial_features, hist_features,hog_features))\n",
    "    return final_features\n",
    "\n",
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def car_features_for_scale(img, ystart, ystop, scale, orient, \n",
    "                           pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    car_boxes = []\n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch,'YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins, bins_range=hist_range)\n",
    "            # Scale features and make a prediction\n",
    "            final_features = np.hstack((spatial_features, hist_features, hog_features)) \n",
    "            xbox_left = np.int(xleft*scale)\n",
    "            ytop_draw = np.int(ytop*scale)\n",
    "            win_draw = np.int(window*scale)\n",
    "            yield final_features,((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart))\n",
    "\n",
    "\n",
    "def find_cars_for_scale(img, ystart, ystop, scale, car_feature_classifier, orient, \n",
    "                        pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    for features,bbox in car_features_for_scale(img, ystart, ystop, scale, orient, \n",
    "                        pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "        if car_feature_classifier(features)>0.5:\n",
    "            yield bbox\n",
    "\n",
    "def visualize_image_features(imgfile,scaler,output_prefix=None):\n",
    "    print(imgfile)\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    plt.subplot(221)\n",
    "    image = img_read(imgfile)\n",
    "    plt.imshow(image)\n",
    "    raw_features = image_features(image,cspace=cspace,spatial_size=(spatial,spatial),hist_bins=hist_bins,hist_range=hist_range)\n",
    "    converted_image = convert_color(image, cspace)\n",
    "    hog_features,hog_image_0 = get_hog_features(converted_image[:,:,0],\n",
    "                                              num_orientation_bins,pix_per_cell,cell_per_block,vis=True)\n",
    "    hog_features1,hog_image_1 = get_hog_features(converted_image[:,:,1],\n",
    "                                              num_orientation_bins,pix_per_cell,cell_per_block,vis=True)\n",
    "    hog_features2,hog_image_2 = get_hog_features(converted_image[:,:,2],\n",
    "                                              num_orientation_bins,pix_per_cell,cell_per_block,vis=True)\n",
    "    f = lambda x : np.dstack([x/np.max(x)]*3)\n",
    "    h0 = f(hog_image_0)\n",
    "    h1 = f(hog_image_1)\n",
    "    h2 = f(hog_image_2)\n",
    "    print('sizes of stacked images')\n",
    "    for i in [h0,h1,h2]:\n",
    "        print(np.max(i),i.dtype,i.shape)\n",
    "    print('hog data done')\n",
    "    if output_prefix is not None:\n",
    "        img_write(img=hog_image_0,img_fname=output_prefix+'hog_image_0.jpg')\n",
    "        img_write(img=hog_image_1,img_fname=output_prefix+'hog_image_1.jpg')\n",
    "        img_write(img=hog_image_2,img_fname=output_prefix+'hog_image_2.jpg')\n",
    "        img_write(img=concat_images(images=[image,h0,h1,h2]),\n",
    "                  img_fname=output_prefix+'hog_combined.jpg')\n",
    "    normalized_features = scaler.transform(raw_features.reshape((1,-1)))\n",
    "    plt.title('Original Image')\n",
    "    plt.subplot(222)\n",
    "    plt.plot(raw_features)\n",
    "    plt.title('Raw Features')\n",
    "    plt.subplot(223)\n",
    "    plt.plot(normalized_features[0])\n",
    "    plt.title('Normalized Features')\n",
    "    plt.subplot(224)\n",
    "    plt.imshow(hog_image_0)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def tune_hyperparams(X,y):\n",
    "    #parameters = {'kernel':['linear', 'rbf'], 'C':[100,500,1000,2000],'gamma':[0.0002,0.002,0.02,0.00002]}\n",
    "    #svr = SVC()\n",
    "    parameters = {'C':[1000]}\n",
    "    svr = LinearSVC()\n",
    "    clf = GridSearchCV(svr, parameters,verbose=3)\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "def accuracy(mdl,X,y):\n",
    "    pred = mdl.predict(X)\n",
    "    return accuracy_score(pred,y)\n",
    "\n",
    "def compute_model():\n",
    "    def feature_calculator(images):\n",
    "        return [image_features(img,cspace=cspace,spatial_size=(spatial,spatial),\n",
    "                               hist_bins=hist_bins,hist_range=hist_range) for img in images]\n",
    "\n",
    "    features = feature_calculator([img_read(x) for x in cars+non_cars])\n",
    "    feature_scaler = StandardScaler().fit(features)\n",
    "    features = feature_scaler.transform(features)\n",
    "    labels = np.hstack((np.ones(shape=(len(cars),)),np.zeros(shape=(len(non_cars),))))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "    model = tune_hyperparams(X_train,y_train)\n",
    "    print('train_accuracy : ',accuracy(model,X_train,y_train),X_train.shape,y_train.shape)\n",
    "    print('test_accuracy  : ',accuracy(model,X_test,y_test),X_test.shape,y_test.shape)\n",
    "    return model,feature_scaler\n",
    "\n",
    "def draw_boxes(img, bboxes, color=blue, thick=6):\n",
    "    imcopy = np.copy(img)\n",
    "    for bbox in bboxes:\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    return imcopy\n",
    "    \n",
    "    \n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    x_start_stop = list(x_start_stop)\n",
    "    y_start_stop = list(y_start_stop)\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    window_list = []\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    return window_list\n",
    "\n",
    "def subwindow(image,box):\n",
    "    ((xmin,ymin),(xmax,ymax)) = box\n",
    "    return image[ymin:ymax,xmin:xmax]\n",
    "\n",
    "def multires_slide_windows(img):\n",
    "    slide_window_args=[((None,None),(400,None),(320,320),(0.75,0.75),red),\n",
    "                       ((None,None),(400,None),(256,256),(0.75,0.75),green),\n",
    "                       ((None,None),(400,628),(128,128),(0.5,0.5),blue),\n",
    "                       ((None,None),(400,628),(64,64),(0.5,0.5),white)]\n",
    "    multires_windows = []\n",
    "    for x_start_stop,y_start_stop,xy_window,xy_overlap,color in slide_window_args:\n",
    "        multires_windows.append((xy_window,slide_window(img,x_start_stop,y_start_stop,xy_window,xy_overlap),color))\n",
    "    return multires_windows\n",
    "\n",
    "def draw_multires_windows(img,multires_windows):\n",
    "    return concat_images([draw_boxes(img,boxes,color) for xy_window,boxes,color in multires_windows])\n",
    "\n",
    "def concat_images(images):\n",
    "    for i in images:\n",
    "        print(i.shape)\n",
    "    num_images_per_row = int(np.sqrt(len(images)))\n",
    "    if len(images)>num_images_per_row*num_images_per_row:\n",
    "        num_images_per_row +=1\n",
    "    num_rows = int(len(images)/num_images_per_row)\n",
    "    if len(images)>num_rows*num_images_per_row:\n",
    "        num_rows+=1\n",
    "    num_blank_images = num_images_per_row *num_rows - len(images)\n",
    "    images += [np.zeros_like(images[0])]*num_blank_images\n",
    "    return np.vstack([np.hstack(images[i*num_images_per_row:(i+1)*num_images_per_row]) for i in range(num_rows)])\n",
    "\n",
    "def is_car(fname,car_classifier):\n",
    "    img = img_read(fname)\n",
    "    prediction = car_classifier([img])\n",
    "    return prediction\n",
    "\n",
    "        \n",
    "def find_cars_old(frame,car_image_classifier):\n",
    "    bboxes = list(itertools.chain(*[boxes for _,boxes,_ in multires_slide_windows(frame)]))\n",
    "    images = [subwindow(frame,bbox) for bbox in bboxes]\n",
    "    return [bbox for bbox,label in zip(bboxes,[car_image_classifier(x) for x in images]) if label>0.5]\n",
    "\n",
    "def find_cars(frame,car_feature_classifier):\n",
    "    def helper(ystart,ystop,scale):\n",
    "        return find_cars_for_scale(frame, ystart, ystop, scale, car_feature_classifier, num_orientation_bins, \n",
    "                                   pix_per_cell, cell_per_block, (spatial,spatial), hist_bins)\n",
    "    bounds = [(300,720,4.0),(300,628,3.0),(300,628,2.0),(300,628,1.5),(300,628,1.0),(300,628,0.8)]\n",
    "    return list(itertools.chain(*[helper(*x) for x in bounds]))\n",
    "\n",
    "def genvideo(input_video_file,output_video_file,frame_trf):\n",
    "    test_clip = VideoFileClip(input_video_file)\n",
    "    new_clip = test_clip.fl_image(frame_trf) #NOTE: this function expects color images!!\n",
    "    new_clip.write_videofile(output_video_file, audio=False)\n",
    "    \n",
    "def showvideo(vfile):    \n",
    "    vtemplate=\"\"\"<video width=\"640\" height=\"300\" controls><source src=\"{0}\" type=\"video/mp4\"></video>\"\"\"\n",
    "    return HTML(vtemplate.format(vfile))\n",
    "\n",
    "def labeled_bboxes(labels):\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        yield bbox\n",
    "\n",
    "frame_id = 0        \n",
    "def find_cars_in_video(input_video_file,output_video_file,car_feature_clf,write_component_images=False):\n",
    "    global frame_id\n",
    "    heatmaps = deque(maxlen=5)\n",
    "    frame_id = 0\n",
    "    def draw_car_bboxes(frame):\n",
    "        global frame_id\n",
    "        frame_id=frame_id+1\n",
    "        frame_prefix = 'frames/frame_%03d'%(frame_id,)\n",
    "        frame_float = frame.astype(np.float32)/255\n",
    "        bboxes = find_cars(frame_float,car_feature_clf)\n",
    "        heatmaps.append(add_heat(np.zeros_like(frame),bboxes))\n",
    "        num_frames_available = len(heatmaps)\n",
    "        cum_heatmap = np.zeros_like(frame_float)\n",
    "        for i in range(num_frames_available):\n",
    "            cum_heatmap += heatmaps[-(i+1)]\n",
    "        cum_heat_image = cum_heatmap*(255/np.max(cum_heatmap))\n",
    "        cum_heatmap[cum_heatmap<=(num_frames_available*7)] = 0\n",
    "        cum_heatmap[cum_heatmap!=0]=255\n",
    "        labels = label(cum_heatmap)\n",
    "        deduped_bboxes = labeled_bboxes(labels)\n",
    "        frame_with_bboxes = draw_boxes(frame,bboxes)\n",
    "        frame_with_deduped_bboxes = draw_boxes(frame,deduped_bboxes)\n",
    "        heat_img = heatmaps[-1]*(255/np.max(heatmaps[-1]))\n",
    "        combined_image = concat_images([frame,frame_with_bboxes,cum_heatmap,cum_heat_image,heat_img,frame_with_deduped_bboxes])\n",
    "        if write_component_images:\n",
    "            img_write(frame_prefix+'_cum_heat.jpg',cum_heat_image)\n",
    "            img_write(frame_prefix+'_heat.jpg',heat_img)\n",
    "            img_write(frame_prefix+'.jpg',frame)\n",
    "            img_write(frame_prefix+'_bboxes.jpg',frame_with_bboxes)\n",
    "            img_write(frame_prefix+'_deduped_bboxes.jpg',frame_with_deduped_bboxes)\n",
    "            img_write(frame_prefix+'_combined.jpg',combined_image)\n",
    "        return combined_image#frame_with_deduped_bboxes\n",
    "    genvideo(input_video_file,output_video_file,draw_car_bboxes)\n",
    "    \n",
    "def add_heat(heatmap, bbox_list):\n",
    "    for box in bbox_list:\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    return heatmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ................. C=1000, score=0.9797363761558135, total= 1.0min\n",
      "[CV] C=1000 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=1000, score=0.9820971867007673, total=  46.7s\n",
      "[CV] C=1000 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=1000, score=0.9805233130041314, total=  45.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy :  1.0 (15249, 10224) (15249,)\n",
      "test_accuracy  :  0.984023432299 (7511, 10224) (7511,)\n"
     ]
    }
   ],
   "source": [
    "recompute_model = False\n",
    "recompute_model = True\n",
    "if recompute_model:\n",
    "    scaled_feature_classifier,feature_scaler=compute_model()\n",
    "    with open('model.p','wb') as model_file:\n",
    "        pickle.dump( scaled_feature_classifier, model_file )\n",
    "    with open('feature_scaler.p','wb') as scaler_file:\n",
    "        pickle.dump( feature_scaler, scaler_file)\n",
    "else:\n",
    "    with open('model.p','rb') as model_file:    \n",
    "        scaled_feature_classifier = pickle.load(model_file)    \n",
    "    with open('feature_scaler.p','rb') as scaler_file:\n",
    "        feature_scaler = pickle.load(scaler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image_features(imgfile=cutouts[5],scaler=feature_scaler,output_prefix='output_images/cutout5_')\n",
    "visualize_image_features(imgfile=non_cars[10],scaler=feature_scaler,output_prefix='output_images/noncar_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "car_feature_classifier = lambda feature:scaled_feature_classifier.predict(feature_scaler.transform(feature.reshape(1, -1)))\n",
    "car_image_classifier = lambda image:car_feature_classifier(image_features(image, cspace, (spatial,spatial), hist_bins, hist_range).reshape(1, -1))\n",
    "find_cars_in_video(test_video,test_video_output,car_feature_classifier,write_component_images=True)\n",
    "showvideo(test_video_output)\n",
    "find_cars_in_video(project_video,project_video_output,car_feature_classifier)\n",
    "showvideo(project_video_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = img_read(sample_frame)\n",
    "frame_float = frame.astype(np.float32)/255\n",
    "bboxes = find_cars(frame_float,car_feature_classifier)\n",
    "bboxes_old = find_cars_old(car_image_classifier=car_image_classifier,frame=frame_float)\n",
    "ret_old = draw_boxes(bboxes=bboxes_old,img=frame)\n",
    "ret = draw_boxes(bboxes=bboxes,img=frame)\n",
    "plt.imshow(ret)\n",
    "plt.show()\n",
    "plt.imshow(ret_old)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
